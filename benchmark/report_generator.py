#!/usr/bin/env python3
"""
Report Generator cho Graph Summarization Benchmark
T·∫°o b√°o c√°o markdown t·ª± ƒë·ªông t·ª´ k·∫øt qu·∫£ benchmark
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from datetime import datetime
import yaml
import json
import argparse

class BenchmarkReportGenerator:
    """T·ª± ƒë·ªông generate b√°o c√°o t·ª´ k·∫øt qu·∫£ benchmark"""
    
    def __init__(self, results_file: str, config_file: str = "config/config.yaml"):
        self.results_file = results_file
        self.config_file = config_file
        
        # Load data
        self.df = pd.read_csv(results_file)
        with open(config_file, 'r') as f:
            self.config = yaml.safe_load(f)
            
        # Setup matplotlib cho ti·∫øng Vi·ªát
        plt.rcParams['font.family'] = ['DejaVu Sans', 'Arial Unicode MS']
        
    def generate_report(self, output_file: str = None):
        """Generate b√°o c√°o ho√†n ch·ªânh"""
        
        if output_file is None:
            output_file = self.config['output']['report_file']
            
        report_content = self._generate_markdown_report()
        
        # Save report
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
            
        print(f"‚úÖ B√°o c√°o ƒë√£ ƒë∆∞·ª£c t·∫°o: {output_file}")
        
        # Generate plots
        self._generate_plots()
        
    def _generate_markdown_report(self) -> str:
        """Generate n·ªôi dung markdown"""
        
        report = f"""# B√ÅO C√ÅO TH·ª∞C NGHI·ªÜM GRAPH SUMMARIZATION

**Ng√†y t·∫°o:** {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}

**H·ªá th·ªëng benchmark:** Advanced Graph Summarization Benchmark System

---

## 1. T·ªîNG QUAN TH·ª∞C NGHI·ªÜM

B√°o c√°o n√†y tr√¨nh b√†y k·∫øt qu·∫£ th·ª±c nghi·ªám c√°c thu·∫≠t to√°n graph summarization tr√™n c√°c b·ªô d·ªØ li·ªáu ƒë·ªì th·ªã Internet, d·ª±a tr√™n nghi√™n c·ª©u **"Graph Summarization: Compactness Meets Efficiency"** (SIGMOD 2024).

### 1.1. Thu·∫≠t to√°n ƒë∆∞·ª£c ƒë√°nh gi√°

{self._get_algorithms_summary()}

### 1.2. B·ªô d·ªØ li·ªáu

{self._get_datasets_summary()}

### 1.3. M√¥i tr∆∞·ªùng th·ª±c nghi·ªám

- **H·ªá ƒëi·ªÅu h√†nh:** {self._get_system_info()}
- **C·∫•u h√¨nh ph·∫ßn c·ª©ng:** Multi-threading v·ªõi {self._get_thread_count()} threads
- **Timeout:** {self.config['benchmark']['timeout']} gi√¢y cho m·ªói thu·∫≠t to√°n

---

## 2. K·∫æT QU·∫¢ TH·ª∞C NGHI·ªÜM

### 2.1. Hi·ªáu nƒÉng T√≥m t·∫Øt ƒê·ªì th·ªã

{self._generate_summarization_performance_table()}

### 2.2. So s√°nh Th·ªùi gian Th·ª±c thi

{self._generate_execution_time_analysis()}

### 2.3. Ch·∫•t l∆∞·ª£ng T√≥m t·∫Øt (Compression Ratio)

{self._generate_compression_analysis()}

### 2.4. Hi·ªáu nƒÉng Truy v·∫•n tr√™n ƒê·ªì th·ªã T√≥m t·∫Øt

{self._generate_query_performance_analysis()}

---

## 3. PH√ÇN T√çCH CHI TI·∫æT

### 3.1. Hi·ªáu qu·∫£ theo Dataset

{self._generate_dataset_analysis()}

### 3.2. Resource Usage Analysis

{self._generate_resource_analysis()}

---

## 4. K·∫æT LU·∫¨N V√Ä ƒê√ÅNH GI√Å

{self._generate_conclusions()}

---

## 5. PH·ª§ L·ª§C

### 5.1. C·∫•u h√¨nh Chi ti·∫øt

```yaml
{yaml.dump(self.config, default_flow_style=False, allow_unicode=True)}
```

### 5.2. Raw Data Summary

- **T·ªïng s·ªë k·∫øt qu·∫£:** {len(self.df)}
- **Datasets ƒë∆∞·ª£c test:** {len(self.df['dataset'].unique())}
- **Algorithms ƒë∆∞·ª£c test:** {len(self.df[self.df['algorithm'] != 'Original']['algorithm'].unique())}

---

*B√°o c√°o ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông b·ªüi Advanced Graph Summarization Benchmark System*
"""
        return report
        
    def _get_algorithms_summary(self) -> str:
        """T√≥m t·∫Øt c√°c thu·∫≠t to√°n"""
        algorithms = self.df[self.df['algorithm'] != 'Original']['algorithm'].unique()
        
        algo_descriptions = {
            'mags': '**MAGS**: MinHash Assisted Graph Summarization - thu·∫≠t to√°n ch√≠nh t·ª´ paper',
            'mags_dm': '**MAGS-DM**: Divide-and-Merge variant c·ªßa MAGS cho kh·∫£ nƒÉng m·ªü r·ªông t·ªët h∆°n',
            'ldme': '**LDME**: Thu·∫≠t to√°n baseline ƒë·ªÉ so s√°nh'
        }
        
        summary = []
        for algo in algorithms:
            if algo in algo_descriptions:
                summary.append(f"- {algo_descriptions[algo]}")
            else:
                summary.append(f"- **{algo.upper()}**: Thu·∫≠t to√°n {algo}")
                
        return '\n'.join(summary)
        
    def _get_datasets_summary(self) -> str:
        """T√≥m t·∫Øt datasets"""
        datasets = self.df['dataset'].unique()
        
        summary = []
        for dataset in datasets:
            if dataset in self.config['datasets']:
                config = self.config['datasets'][dataset]
                summary.append(f"- **{dataset}**: {config['description']} ({config['nodes']:,} nodes, {config['edges']:,} edges)")
            else:
                summary.append(f"- **{dataset}**: Dataset {dataset}")
                
        return '\n'.join(summary)
        
    def _get_system_info(self) -> str:
        """Th√¥ng tin h·ªá th·ªëng"""
        import platform
        return f"{platform.system()} {platform.release()}"
        
    def _get_thread_count(self) -> int:
        """S·ªë threads ƒë∆∞·ª£c s·ª≠ d·ª•ng"""
        return self.config['algorithms']['mags']['parameters']['threads']
        
    def _generate_summarization_performance_table(self) -> str:
        """B·∫£ng hi·ªáu nƒÉng t√≥m t·∫Øt"""
        
        # Filter summarization results
        summ_df = self.df[self.df['algorithm'] != 'Original'].copy()
        
        if summ_df.empty:
            return "*Kh√¥ng c√≥ d·ªØ li·ªáu t√≥m t·∫Øt*"
            
        # Create summary table
        pivot_time = summ_df.pivot_table(
            values='summarization_time_ms', 
            index='dataset', 
            columns='algorithm', 
            aggfunc='mean'
        ).round(0)
        
        pivot_compression = summ_df.pivot_table(
            values='summary_size_ratio', 
            index='dataset', 
            columns='algorithm', 
            aggfunc='mean'
        ).round(3)
        
        table_md = "#### Th·ªùi gian T√≥m t·∫Øt (ms)\n\n"
        table_md += pivot_time.to_markdown() + "\n\n"
        
        table_md += "#### T·ª∑ l·ªá N√©n (Compression Ratio)\n\n"
        table_md += pivot_compression.to_markdown() + "\n\n"
        
        return table_md
        
    def _generate_execution_time_analysis(self) -> str:
        """Ph√¢n t√≠ch th·ªùi gian th·ª±c thi"""
        
        summ_df = self.df[self.df['algorithm'] != 'Original'].copy()
        
        if summ_df.empty:
            return "*Kh√¥ng c√≥ d·ªØ li·ªáu ph√¢n t√≠ch*"
            
        # Statistics by algorithm
        stats = summ_df.groupby('algorithm')['summarization_time_ms'].agg([
            'mean', 'std', 'min', 'max'
        ]).round(0)
        
        analysis = "#### Th·ªëng k√™ Th·ªùi gian Th·ª±c thi\n\n"
        analysis += stats.to_markdown() + "\n\n"
        
        # Find best performer
        best_algo = stats['mean'].idxmin()
        best_time = stats.loc[best_algo, 'mean']
        
        analysis += f"**Thu·∫≠t to√°n nhanh nh·∫•t:** {best_algo.upper()} v·ªõi th·ªùi gian trung b√¨nh {best_time:.0f}ms\n\n"
        
        return analysis
        
    def _generate_compression_analysis(self) -> str:
        """Ph√¢n t√≠ch ch·∫•t l∆∞·ª£ng n√©n"""
        
        summ_df = self.df[self.df['algorithm'] != 'Original'].copy()
        
        if summ_df.empty:
            return "*Kh√¥ng c√≥ d·ªØ li·ªáu n√©n*"
            
        # Compression statistics
        comp_stats = summ_df.groupby('algorithm')['summary_size_ratio'].agg([
            'mean', 'std', 'min', 'max'
        ]).round(3)
        
        analysis = "#### Th·ªëng k√™ T·ª∑ l·ªá N√©n\n\n"
        analysis += comp_stats.to_markdown() + "\n\n"
        
        # Find best compressor
        best_compressor = comp_stats['mean'].idxmax()
        best_ratio = comp_stats.loc[best_compressor, 'mean']
        
        analysis += f"**N√©n t·ªët nh·∫•t:** {best_compressor.upper()} v·ªõi t·ª∑ l·ªá n√©n trung b√¨nh {best_ratio:.1%}\n\n"
        
        return analysis
        
    def _generate_query_performance_analysis(self) -> str:
        """Ph√¢n t√≠ch hi·ªáu nƒÉng truy v·∫•n"""
        
        # Compare query performance on original vs summarized graphs
        original_df = self.df[self.df['algorithm'] == 'Original']
        summ_df = self.df[self.df['algorithm'] != 'Original']
        
        if original_df.empty or summ_df.empty:
            return "*Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ so s√°nh*"
            
        analysis = "#### So s√°nh Hi·ªáu nƒÉng Truy v·∫•n\n\n"
        
        # PageRank analysis
        analysis += "**PageRank Performance:**\n\n"
        
        pr_comparison = []
        for dataset in original_df['dataset'].unique():
            orig_time = original_df[original_df['dataset'] == dataset]['pagerank_time_ms'].iloc[0]
            
            for algo in summ_df['algorithm'].unique():
                algo_data = summ_df[(summ_df['dataset'] == dataset) & (summ_df['algorithm'] == algo)]
                if not algo_data.empty:
                    summ_time = algo_data['pagerank_time_ms'].iloc[0]
                    accuracy = algo_data['pagerank_accuracy'].iloc[0]
                    speedup = orig_time / summ_time
                    
                    pr_comparison.append({
                        'Dataset': dataset,
                        'Algorithm': algo,
                        'Original Time (ms)': f"{orig_time:.0f}",
                        'Summary Time (ms)': f"{summ_time:.0f}",
                        'Speedup': f"{speedup:.1f}x",
                        'Accuracy': f"{accuracy:.1%}"
                    })
        
        if pr_comparison:
            pr_df = pd.DataFrame(pr_comparison)
            analysis += pr_df.to_markdown(index=False) + "\n\n"
            
        return analysis
        
    def _generate_dataset_analysis(self) -> str:
        """Ph√¢n t√≠ch theo dataset"""
        
        analysis = ""
        
        for dataset in self.df['dataset'].unique():
            dataset_df = self.df[self.df['dataset'] == dataset]
            
            analysis += f"#### {dataset}\n\n"
            
            if dataset in self.config['datasets']:
                config = self.config['datasets'][dataset]
                analysis += f"- **M√¥ t·∫£:** {config['description']}\n"
                analysis += f"- **K√≠ch th∆∞·ªõc:** {config['nodes']:,} nodes, {config['edges']:,} edges\n"
                analysis += f"- **Lo·∫°i:** {config['type']}\n\n"
                
            # Performance summary for this dataset
            perf_summary = dataset_df[dataset_df['algorithm'] != 'Original'].groupby('algorithm').agg({
                'summarization_time_ms': 'mean',
                'summary_size_ratio': 'mean'
            }).round(2)
            
            if not perf_summary.empty:
                analysis += "**Hi·ªáu nƒÉng tr√™n dataset n√†y:**\n\n"
                analysis += perf_summary.to_markdown() + "\n\n"
                
        return analysis
        
    def _generate_resource_analysis(self) -> str:
        """Ph√¢n t√≠ch resource usage"""
        
        summ_df = self.df[self.df['algorithm'] != 'Original'].copy()
        
        if summ_df.empty or 'memory_peak_mb' not in summ_df.columns:
            return "*Kh√¥ng c√≥ d·ªØ li·ªáu resource usage*"
            
        # Memory usage analysis
        memory_stats = summ_df.groupby('algorithm')['memory_peak_mb'].agg([
            'mean', 'std', 'max'
        ]).round(1)
        
        analysis = "#### Memory Usage (MB)\n\n"
        analysis += memory_stats.to_markdown() + "\n\n"
        
        # CPU usage analysis  
        if 'cpu_avg_percent' in summ_df.columns:
            cpu_stats = summ_df.groupby('algorithm')['cpu_avg_percent'].agg([
                'mean', 'std', 'max'
            ]).round(1)
            
            analysis += "#### CPU Usage (%)\n\n"
            analysis += cpu_stats.to_markdown() + "\n\n"
            
        return analysis
        
    def _generate_conclusions(self) -> str:
        """Generate k·∫øt lu·∫≠n"""
        
        summ_df = self.df[self.df['algorithm'] != 'Original'].copy()
        
        if summ_df.empty:
            return "*Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ k·∫øt lu·∫≠n*"
            
        conclusions = []
        
        # Best algorithm by speed
        speed_ranking = summ_df.groupby('algorithm')['summarization_time_ms'].mean().sort_values()
        fastest = speed_ranking.index[0]
        conclusions.append(f"- **T·ªëc ƒë·ªô:** {fastest.upper()} l√† thu·∫≠t to√°n nhanh nh·∫•t v·ªõi th·ªùi gian trung b√¨nh {speed_ranking.iloc[0]:.0f}ms")
        
        # Best algorithm by compression
        comp_ranking = summ_df.groupby('algorithm')['summary_size_ratio'].mean().sort_values(ascending=False)
        best_comp = comp_ranking.index[0]
        conclusions.append(f"- **Ch·∫•t l∆∞·ª£ng n√©n:** {best_comp.upper()} ƒë·∫°t t·ª∑ l·ªá n√©n cao nh·∫•t {comp_ranking.iloc[0]:.1%}")
        
        # Query performance
        if 'pagerank_time_ms' in summ_df.columns:
            avg_speedup = []
            for dataset in self.df['dataset'].unique():
                orig_time = self.df[(self.df['dataset'] == dataset) & (self.df['algorithm'] == 'Original')]['pagerank_time_ms']
                if not orig_time.empty:
                    orig_time = orig_time.iloc[0]
                    summ_times = summ_df[summ_df['dataset'] == dataset]['pagerank_time_ms']
                    if not summ_times.empty:
                        avg_speedup.extend([orig_time / t for t in summ_times])
                        
            if avg_speedup:
                overall_speedup = np.mean(avg_speedup)
                conclusions.append(f"- **Hi·ªáu nƒÉng truy v·∫•n:** Trung b√¨nh nhanh h∆°n {overall_speedup:.1f}x so v·ªõi ƒë·ªì th·ªã g·ªëc")
                
        conclusions.append("- **T·ªïng k·∫øt:** C√°c thu·∫≠t to√°n MAGS/MAGS-DM cho th·∫•y hi·ªáu qu·∫£ t·ªët trong vi·ªác t√≥m t·∫Øt ƒë·ªì th·ªã Internet v·ªõi th·ªùi gian h·ª£p l√Ω v√† ch·∫•t l∆∞·ª£ng cao")
        
        return '\n'.join(conclusions)
        
    def _generate_plots(self):
        """Generate c√°c bi·ªÉu ƒë·ªì minh h·ªça"""
        
        # Create plots directory
        plots_dir = Path("plots")
        plots_dir.mkdir(exist_ok=True)
        
        summ_df = self.df[self.df['algorithm'] != 'Original'].copy()
        
        if summ_df.empty:
            return
            
        # 1. Execution time comparison
        plt.figure(figsize=(12, 6))
        sns.boxplot(data=summ_df, x='algorithm', y='summarization_time_ms')
        plt.title('So s√°nh Th·ªùi gian Th·ª±c thi c√°c Thu·∫≠t to√°n')
        plt.xlabel('Thu·∫≠t to√°n')
        plt.ylabel('Th·ªùi gian (ms)')
        plt.yscale('log')
        plt.tight_layout()
        plt.savefig(plots_dir / 'execution_time_comparison.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # 2. Compression ratio comparison
        plt.figure(figsize=(12, 6))
        sns.boxplot(data=summ_df, x='algorithm', y='summary_size_ratio')
        plt.title('So s√°nh T·ª∑ l·ªá N√©n c√°c Thu·∫≠t to√°n')
        plt.xlabel('Thu·∫≠t to√°n')
        plt.ylabel('T·ª∑ l·ªá N√©n')
        plt.tight_layout()
        plt.savefig(plots_dir / 'compression_ratio_comparison.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"‚úÖ Bi·ªÉu ƒë·ªì ƒë√£ ƒë∆∞·ª£c t·∫°o trong th∆∞ m·ª•c {plots_dir}/")

def main():
    """Main function"""
    parser = argparse.ArgumentParser(description="Generate benchmark report")
    parser.add_argument("--results", default="results/benchmark_results.csv",
                       help="Path to benchmark results CSV")
    parser.add_argument("--config", default="config/config.yaml",
                       help="Path to config file")
    parser.add_argument("--output", help="Output report file")
    
    args = parser.parse_args()
    
    try:
        generator = BenchmarkReportGenerator(args.results, args.config)
        generator.generate_report(args.output)
        print("üéâ B√°o c√°o ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng!")
    except Exception as e:
        print(f"‚ùå L·ªói t·∫°o b√°o c√°o: {e}")
        return 1
        
    return 0

if __name__ == "__main__":
    exit(main()) 